
# Retrieval-Augmented Generation (RAG) Project

This repository demonstrates a Retrieval-Augmented Generation (RAG) pipeline using Python, LangChain, Ollama, and ChromaDB. RAG is an advanced technique that combines information retrieval with generative AI models, allowing the system to answer questions based on both stored knowledge and retrieved documents.

## Models Used
- **Embedding Model:** `mxbai-embed-large` (via Ollama)
- **LLM Model:** `llama3.1` (via Ollama)

These models are used for document embedding and question answering in the RAG pipeline. You can change the model names in the scripts to use other supported models if needed.

# Project Level
This project can be considered **intermediate to advanced**. It requires familiarity with Python, LLMs, embeddings, and vector databases. It is suitable for those learning about or prototyping RAG systems.

This repository contains the following files and directories:

- **RR.py**: Main script that builds and runs a basic RAG chain. It loads a PDF, splits it into chunks, embeds the text, stores it in a Chroma vector database, and sets up a retriever and LLM (Ollama) to answer questions using only the retrieved context. Example usage: streaming an answer to a math question from the PDF.
- **RR2.py**: Enhanced RAG script that uses a MultiQueryRetriever. It generates multiple paraphrased queries for better retrieval coverage, combines results, and passes them to the LLM. This improves answer quality for ambiguous or complex questions.
- **see.py**: Utility and testing script. It demonstrates how to inspect the Chroma database, view collection stats, peek at stored documents, and test embedding generation. It also shows how to invoke the RAG chain from RR.py for direct question answering.
- **chroma_db/**: Directory containing database files, including:
  - `chroma.sqlite3`: SQLite3 database file.
  - `db23de41-91d9-42f1-844e-aae2aa4603fe/`: Subdirectory for database storage.
- **__pycache__/**: Python cache directory (auto-generated).


## Getting Started

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd <repository-folder>
   ```
2. **Install Python 3.11 or later.**
3. **Install required packages:**
   Install all dependencies with:
   ```bash
   pip install -r requirements.txt
   ```
4. **Run the scripts:**
   ```bash
   python RR.py
   # or
   python RR2.py
   # or
   python see.py
   ```

## Notes
- This project implements a RAG pipeline: retrieve relevant document chunks and generate answers using an LLM.
- The `chroma_db` folder contains the persistent vector database used for retrieval.
- The `__pycache__` folder is auto-generated by Python and can be ignored.
- You can adapt the scripts to your own PDFs or data sources by changing the input file.
- All required Python packages are listed in `requirements.txt`.

## License
Add your license information here.
